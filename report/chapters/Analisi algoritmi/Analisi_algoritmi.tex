\documentclass[../../Report.tex]{subfiles}
\usepackage[italian]{babel}

\begin{document}
\chapter{Valutazione degli Algoritmi di Classificazione}
Nella presente fase del progetto, è stata effettuata la valutazione di tre algoritmi di classificazione: \textbf{KNN}, \textbf{Random Forest} e \textbf{Gaussian Bayes}. L'obiettivo era quello di eseguire un confronto tra i tre algoritmi e di determinare quale di essi fosse più preciso nel classificare i dati utilizzando il dataset HAR fornito.\\
La valutazione è stata effettuata attraverso la misurazione dell'accuratezza degli algoritmi e il confronto dei risultati ottenuti. Questo ha permesso di determinare quale algoritmo fosse il più adatto per il problema di riconoscimento delle attività svolte dall'utente.\\   

\section{Dataset, data mining e tecnologie utilizzate}
Il dataset utilizzato per l'analisi ci è stato fornito dal prof. Marco Di Felice. Il dataset è composto da 62.584 osservazioni e 13 colonne riguardanti il valore dei sensori di uno smartphone android e l'attività dell'utente, come seguente:

\begin{table}[H]
    \centering
    \begin{tabular}{|l|p{0.7\linewidth}|}
        \hline
        \textbf{accelerometer\#mean} & la media delle osservazioni dell'accelerometro. \\
        \hline
        \textbf{accelerometer\#min} & l'osservazione minima dell'accelerometro. \\
        \hline
        \textbf{accelerometer\#max} & l'osservazione massima dell'accelerometro. \\
        \hline
        \textbf{accelerometer\#std} & la deviazione standard delle osservazioni dell'accelerometro. \\
        \hline
        \textbf{gyroscope\#mean} & la media delle osservazioni del giroscopio. \\
        \hline
        \textbf{gyroscope\#min} &  l'osservazione minima del giroscopio. \\
        \hline
        \textbf{gyroscope\#max} &  l'osservazione massima del giroscopio. \\
        \hline
        \textbf{gyroscope\#std} & la deviazione standard delle osservazioni del giroscopio. \\
        \hline
        \textbf{gyroscopeuncalibrated\#mean} & la media delle osservazioni del giroscopio non calibrato. \\
        \hline
        \textbf{gyroscopeuncalibrated\#min} &  l'osservazione minima del giroscopio non calibrato. \\
        \hline
        \textbf{gyroscopeuncalibrated\#max} & l'osservazione massima del giroscopio non calibrato. \\
        \hline
        \textbf{gyroscopeuncalibrated\#std} & la deviazione standard delle osservazioni del giroscopio non calibrato.\\
        \hline
        \textbf{target} & l'attività svolta dall'utente. \\
        \hline
    \end{tabular}
\end{table}
Le etichette di questo dataset assumono 5 valori differenti:
\begin{itemize}
    \item \textbf{STILL}: l'utente non si muove.
    \item \textbf{WALKING}: l'utente cammina.
    \item \textbf{CAR}: l'utente è in auto.
    \item \textbf{BUS}: l'utente è in bus.
    \item \textbf{TRAIN}: l'utente è in treno. 
\end{itemize}

\subsection{Data mining}
    Per il data mining è stato utilizzato il linguaggio di programmazione \emph{Python} e per il training e prediction dei modelli la libreria \emph{Scikit-learn}. Inoltre, durante la fase di preprocessing e per la gestione dei dati è stata utilizzata la libreria di Python \emph{Pandas}.\\
    Non è stato fatto un grande preprocessing dei dati, in quanto il dataset fornitoci era già di ottima qualità. Per la rimozione dei valori mancanti, abbiamo rimosso solo le righe per le quali mancavano almeno due attributi per ogni classe di sensori. Questo ci ha portato a perdere circa 5000 tuple. Per quelle righe in cui era presente solamente un valore mancante questo è stato sostituito con la media. I dati sono stati lavorati al fine di eliminare i valori NaN e di normalizzare i dati, scalandoli utilizzando la funzione \emph{MinMaxScaling}. Inoltre sono state eliminate tutte le tuple che non riguardavano le attività di interesse (WALKING e DRIVING).\\
    Per tutti e tre gli algoritmi il dataset è stato suddiviso in due parti:
    \begin{itemize}
        \item \textbf{Training}: è stato utilizzato per il training del modello.
        \item \textbf{Testing}: è stato utilizzato per il testing del modello.
    \end{itemize}
    Per il training è stato utilizzato l'80\% dei dati e per il testing il 20\%.\\

\section{Gli algoritmi}
Come già detto precedentemente, in questa fase di valutazione degli algoritmi di classificazione, sono stati considerati tre differenti algoritmi: il \textbf{KNN}, il \textbf{Random Forest} e il \textbf{Gaussian Naive Bayes}.\\
Questi algoritmi rappresentano tre approcci distinti alla risoluzione del problema di classificazione, ciascuno con i suoi punti di forza e limiti. Il \textbf{KNN} utilizza una logica basata sulla vicinanza dei dati, il \textbf{Random Forest} è un algoritmo di ensemble che utilizza molteplici alberi di decisione e il \textbf{Gaussian Naive Bayes} si basa sull'assunzione che le feature sono distribuite normalmente.\\
In questa sezione, verranno descritti in dettaglio ciascuno di questi algoritmi e verrà presentato un confronto tra i loro risultati e le loro prestazioni.
\subsection{KNN}
Per quanto riguarda il KNN è stato deciso di effettuare un tuning degli iperparametri per il KNN, con lo scopo di ottenere una prestazione ottimale del modello.\\
I parametri che sono stati modificati sono stati:
\begin{itemize}
    \item \textbf{n\_neighbors}: rappresenta il numero di vicini considerati nella classificazione
    \item \textbf{weights}: determina il peso dei vicini nella classificazione
    \item \textbf{leaf-size}: rappresenta la dimensione massima di una foglia dell'albero di ricerca
    \item \textbf{p}: determina la potenza della metrica utilizzata nella calcoli della distanza tra i vicini
\end{itemize}
Il tuning degli iperparametri è stato effettuato utilizzando la funzione \emph{GridSearchCV} di \emph{Scikit-learn}. Questa funzione permette di eseguire una ricerca su una griglia di valori per gli iperparametri, testando tutte le possibili combinazioni e selezionando quella che produce la migliore prestazione in termini di accuratezza.\\
L'obiettivo di questa ottimizzazione era quello di migliorare la precisione del modello KNN e di fornire una soluzione ottimale per la classificazione dei dati. Il risultato ottenuto ha dimostrato che l'ottimizzazione degli iperparametri è stata efficace e ha contribuito a migliorare la performance del modello.

\subsubsection{Risultati}
I risultati del tuning degli iperparametri utilizzando il dataset precedentemente descritto sono riportati nella tabella seguente:

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|}
        \hline
         & \textbf{Best value} \\
        \hline
        \textbf{n\_neighbors} & 14 \\
        \hline
        \textbf{weights} & distance \\
        \hline
        \textbf{leaf\_size} & 1 \\
        \hline
        \textbf{p} & 2 \\
        \hline
    \end{tabular}
\end{table}

Con questi parametri siamo riusciti ad ottenere un'accuratezza finale dell'89\%.\\
Facendo training di questo modello con il dataset su cui abbiamo applicato il MinMaxScaling, abbiamo ottenuto un'accuratezza del 90\%.\\
I parametri risultanti dal tuning sono invece:
\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|}
        \hline
         & \textbf{Best value} \\
        \hline
        \textbf{n\_neighbors} & 12 \\
        \hline
        \textbf{weights} & distance \\
        \hline
        \textbf{leaf\_size} & 1 \\
        \hline
        \textbf{p} & 2 \\
        \hline
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.49\textwidth]{ConfusionMatrixKNNUnscaled.png}
    \includegraphics[width=0.49\textwidth]{ConfusionMatrixKNNScaled.png}
    \caption{Matrice di confusione del modello senza scaling (sx) e con scaling (dx)}
    \label{fig:confusion_matrix_KNN}
\end{figure}
Si può notare come questo modello commetta più facilmente errori nel riconoscere la classe DRIVING.\\

\subsection{Random Forest}
\label{sec:random_forest}
Come per il KNN, anche per il Random Forest è stato effettuato un tuning degli iperparametri per ottenere una prestazione ottimale del modello.\
I parametri che sono stati modificati sono stati:
\begin{itemize}
\item \textbf{n\_estimators}: che rappresenta il numero di alberi decisionali nella foresta
\item \textbf{max\_features}: che rappresenta il numero di features da considerare quando si cerca la migliore divisione
\item \textbf{max\_depth}: che rappresenta la profondità massima degli alberi decisionali
\item \textbf{min\_samples\_split}: che rappresenta il numero minimo di campioni richiesti per dividere un nodo interno
\item \textbf{min\_samples\_leaf}: che rappresenta il numero minimo di campioni richiesti per costruire una foglia dell'albero
\item \textbf{bootstrap}: che rappresenta la modalità di campionamento dei dati
\end{itemize}
Il tuning degli iperparametri è stato effettuato utilizzando la funzione \emph{RandomizedSearchCV} di \emph{Scikit-learn}.\\
L'obiettivo di questa ottimizzazione era quello di migliorare la precisione del modello Random Forest e di fornire una soluzione ottimale per la classificazione dei dati. Il risultato ottenuto ha dimostrato che l'ottimizzazione degli iperparametri è stata efficace e ha contribuito a migliorare la performance del modello. La RandomizedSearchCV è stata eseguita per un numero di 100 iterazioni, usando una 5-fold cross validation. Per un totale di 500 fit. In questo caso è stata preferita una RandomizedSearchCV rispetto ad una GridSearchCV poichè il numero di combinazioni di iperparametri da testare è molto elevato e testarli tutti avrebbe richiesto un tempo di esecuzione molto elevato rispetto alla potenza di calcolo disponibile. 

\subsubsection{Risultati}

I risultati del tuning degli iperparametri utilizzando il dataset precedentemente descritto sono riportati nella tabella seguente:

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|}
        \hline
        & \textbf{Best value} \\
        \hline
        \textbf{n\_estimators} & 800 \\
        \hline
        \textbf{max\_depth} & 90 \\
        \hline
        \textbf{min\_samples\_split} & 5 \\
        \hline
        \textbf{min\_samples\_leaf} & 1 \\
        \hline
        \textbf{max\_features} & sqrt \\
        \hline
        \textbf{bootstrap} & False \\
        \hline
    \end{tabular}
\end{table}

Con questi parametri siamo riusciti ad ottenere un'accuratezza finale del 95.24\% utilizzando il dataset su cui non è stato applicato il MinMaxScaling.

Facendo tuning sul modello Random Forest utilizzando il modello con il MinMaxScaling, si è ottenuto un'accuratezza del 89,95\%.\\
I parametri ottenuti dal tuning sono:

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|}
        \hline
        & \textbf{Best value} \\
        \hline
        \textbf{n\_estimators} & 1400 \\
        \hline
        \textbf{max\_depth} & 80 \\
        \hline
        \textbf{min\_samples\_split} & 10 \\
        \hline
        \textbf{min\_samples\_leaf} & 2 \\
        \hline
        \textbf{max\_features} & sqrt \\
        \hline
        \textbf{bootstrap} & True \\
        \hline
    \end{tabular}
\end{table}

Mostriamo adesso i grafici delle Matrici di confusione ottenute per i due modelli Random Forest, uno con il dataset su cui non è stato applicato il MinMaxScaling e l'altro con il dataset su cui è stato applicato il MinMaxScaling.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.49\textwidth]{ConfusionMatrixRFUnscaled.png}
    \includegraphics[width=0.49\textwidth]{ConfusionMatrixRFScaled.png}
    \caption{Matrice di confusione del modello senza scaling (sx) e con scaling (dx)}
    \label{fig:confusion_matrix_rf}
\end{figure}
Queste matrici di confusione mostrano come il modello Random Forest sia ottimo per la classificazione di questo tipo dati. Sia il modello senza scaling che quello con scaling sono in grado di classificare correttamente la maggior parte dei dati, ma è possibile notare cme riescano a riconoscere più facilmente l'etichetta WALKING, rispetto a quella DRIVING, nella quale è presente un errore maggiore. 
\subsection{Gaussian Naive Bayes}
Per quanto riguarda il Gaussian Naive Bayes, abbiamo deciso di utilizzare questo algoritmo per la classificazione dei dati in quanto si tratta di un metodo semplice e veloce per la classificazione basato sull'assunzione che le feature siano distribuite secondo una distribuzione normale.\\
Per questo modello il tuning dei parametri è stato effettuato utilizzando la funzione \emph{GridSearchCV} di \emph{Scikit-learn} solo su un'unico parametro \emph{var\_smoothing}, che rappresenta la varianza della distribuzione normale.\\
%Table 2 column 1 row 
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        &\textbf{Unscaled}& \textbf{Scaled} \\
        \hline
        \textbf{var\_smoothing} & 0.0012328467394420659 & 0.0003511191734215131 \\
        \hline
    \end{tabular}
\end{table}
Nonostante ciò le accuracy sono risultate essere identiche per entrambi i modelli. Mostriamo quindi solo una delle due matrici di confunsione ottenute, essendo esse identiche.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{ConfusionMatrixGNBUnscaled.png}
    \caption{Matrice di confusione }
    \label{fig:confusion_matrix_gaussian}
\end{figure}

\subsubsection{Risultati}
Il modello Gaussian Naive Bayes ha fornito un'accuratezza del 81.82\%, che risulta essere un risultato inferiore rispetto ai modelli KNN e Random Forest.

\section{Confronto dei risultati}
Illustriamo di seguito i risultati completi dei tre modelli precedenti, ottenute utilizzando il dataset precedentemente descritto.

\begin{table}[H]
    \begin{center}
        \begin{tabular}{ |P{2cm}|P{1cm}|P{1cm}|P{1cm}|P{1cm}|P{1cm}|P{1cm}|P{1cm}|P{1cm}|P{1cm}|P{1.8cm}| } 
            \multicolumn{11}{c}{\textbf{Evaluating algorithms}} \\
            \hline
            & \multicolumn{3}{c|}{\textbf{KNN}} & \multicolumn{3}{c|}{\textbf{RF}} & \multicolumn{3}{c|}{\textbf{GNB}} & \\
            \hline
            \rowcolor{lightgray}
            & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{Support} \\
            \hline
            \textbf{0} & 0.88 & 0.92 & 0.90 & 0.95 & 0.95 & 0.95 & 0.76 & 0.98 & 0.86 & 1949 \\
            \hline
            \rowcolor{lightgray}
            \textbf{1} & 0.92 & 0.87 & 0.90 & 0.95 & 0.95 & 0.95 & 0.98 & 0.71 & 0.82 & 2043 \\
            \hline
            \textbf{Accuracy} & \multicolumn{3}{c|}{0.8987975951903807} &\multicolumn{3}{c|}{0.9524048096192385} &\multicolumn{3}{c|}{0.843436873747495}& 3992 \\
            \hline
            \rowcolor{lightgray}
            \textbf{Macro AVG} & 0.90 & 0.90 & 0.90 &0.95  & 0.95 & 0.95 & 0.87 & 0.85 & 0.84 & 3992 \\
            \hline
            \textbf{Weighted AVG} & 0.90 & 0.90 & 0.90 & 0.95 & 0.95 & 0.95 & 0.87 & 0.84 & 0.84 & 3992 \\
            \hline
        \end{tabular}
        \caption{P = Precision, R = Recall e F1 = F1-score}
    \end{center}
\end{table}

Utilizzando il dataset su cui è stato applicato il MinMaxScaling i risultati sono:
\begin{table}[H]
    \begin{center}
        \begin{tabular}{ |P{2cm}|P{1cm}|P{1cm}|P{1cm}|P{1cm}|P{1cm}|P{1cm}|P{1cm}|P{1cm}|P{1cm}|P{1.8cm}| } 
            \multicolumn{11}{c}{\textbf{Evaluating algorithms}} \\
            \hline
            & \multicolumn{3}{c|}{\textbf{KNN}} & \multicolumn{3}{c|}{\textbf{RF}} & \multicolumn{3}{c|}{\textbf{GNB}} & \\
            \hline
            \rowcolor{lightgray}
            & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{Support} \\
            \hline
            \textbf{0} & 0.88 & 0.88 & 0.92 & 0.87 & 0.93 & 0.90 & 0.76 & 0.98 & 0.86 & 1949 \\
            \hline
            \rowcolor{lightgray}
            \textbf{1} & 0.92 & 0.88 & 0.90 & 0.93 & 0.87 & 0.90 & 0.98 & 0.71 & 0.82 & 2043 \\
            \hline
            \textbf{Accuracy} & \multicolumn{3}{c|}{0.8997995991983968} &\multicolumn{3}{c|}{0.8995490981963928} &\multicolumn{3}{c|}{0.843436873747495}& 3992 \\
            \hline
            \rowcolor{lightgray}
            \textbf{Macro AVG} & 0.90 & 0.90 & 0.90 &0.90  & 0.90 & 0.90 & 0.87 & 0.85 & 0.84 & 3992 \\
            \hline
            \textbf{Weighted AVG} & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 &0.90  & 0.87 & 0.84 & 0.84 & 3992 \\
            \hline

        \end{tabular}
        \caption{P = Precision, R = Recall e F1 = F1-score}
    \end{center}
\end{table}

Prima di confrontare i tre modelli tra loro, confrontiamo le differenze nell'applicazione per ogni modello dello scaling dei valori. Per quanto riguarda il Gaussian Naive Bayes i risultati sono praticamente identici, mentre per il modello KNN c'è un miglioramento di circa un 0.1\% dell'accuratezza. Per il modello Random Forest invece c'è un peggioramento dell'accuratezza di circa il 6\%, un risultato molto significativo. Dati i risultati ottenuti abbiamo tralasciato quindi questa tecnica. Riguardo invece al confronto tra i tre modelli, con ben un 6\% di accuratezza in più il modello Random Forest è il modello migliore.
\section{Accuratezza sistema Har integrato}
Dati i precedenti risultati, abbiamo valutato l'accuratezza del sistema di HAR integrato nell'applicazione e offerto dalla libreria \emph{flutter\_activity\_recognition}. Per farlo, data l'impossibilità di testare la libreria con il dataset utilizzato per testare i modelli precedentemente presentati, abbiamo raccolto un piccolo testbed tramite esperimenti reali. Abbiamo raccolto 1147
record, formati dai dati dei sensori e due colonne target: il target riconosciuto dall'utente (la ground truth) e il target riconosciuto dalla libreria. Proprio il confronto tra questi target ci ha permesso di valutare l'accuratezza del sistema. Il risultato ottenuto è un'accuratezza del \textbf{91,02}\%. Dato che il dataset è stato raccolto da noi stessi e che abbiamo previsto l'apparizione di un toast sull'app mobile quando la libreria riconosceva un'attività, abbiamo potuto verificare sul campo quali fossero le situazioni che portavano in errore la libreria. Dobbiamo dire che sul riconscimento di un'attività di WALKING o STILL la libreria si presenta solida. Qualche errore è stato commesso durante il riconoscimento di attività IN\_VEICHLE, in caso di grandi frenate o curve particolari portavano la libreria per qualche secondo a riconoscere UNKNOWN. Nel grafico mostriamo un istogramma che mette a confronto le tuple per ogni classe target e il numero di predizioni corrette fatte. Come si può notare la maggior parte degli errori è stata commessa nella classe STILL, questo però è dipeso anche dal nostro metodo di raccolta dei dati, in cui raccoglievamo tuple ad intervalli regolari di tempo e non solo quando la libreria riconosceva una nuova attività.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{HarByClass.png}
    \caption{Istogramma che mette a confronto le tuple per ogni classe target e il numero di predizioni corrette fatte}
    \label{fig:accuracy}
\end{figure}

\section{Implementazione del Random Forest nell'app}
Dati i risultati ottenuti nella sezione \ref{sec:random_forest}, comparati con i risultati ottenuti dagli altri due modelli, abbiamo scelto il Random Forest come algoritmo di classificazione da implementare direttamente nell'applicazione. Nonostante nella fase precedente è stato allenato un classificatore binario, implementando direttamente nell'applicazione questo tipo di classificatore fa si che l'applicazione non sia in grado di riconoscere quando l'utente è fermo, riconoscendo comunque un'attività. Per motivi di completezza quindi, abbiamo deciso di trasformare il classificatore da binario a ternario riconoscendo WALKING, DRIVING e STILL. Data la poca disponibilità di dati raccolti da noi stessi, questo è stato allenato su una combinazione dei dati raccolti direttamente tramite l'applicazione e dei dati del dataset HAR, discusso nelle sezioni precedenti. Anche il successivo testing è stato fatto su una combinazione dei dati provenienti da queste due diverse fonti.\\
Data la variazione del dataset, abbiamo deciso di effettuare nuovamente il tuning degli iperparametri del modello.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|}
        \hline
        & \textbf{Best value} \\
        \hline
        \textbf{n\_estimators} & 800 \\
        \hline
        \textbf{max\_depth} & 90 \\
        \hline
        \textbf{min\_samples\_split} & 5 \\
        \hline
        \textbf{min\_samples\_leaf} & 1 \\
        \hline
        \textbf{max\_features} & sqrt \\
        \hline
        \textbf{bootstrap} & False \\
        \hline
    \end{tabular}
\end{table}
Nella tabella precedente possiamo vedere i migliori valori trovati per ogni iperparametro, mentre nella successiva mostriamo i risultati ottenuti dalla fase di testing del nostro modello. 

\begin{table}[H]
    \begin{center}
        \begin{tabular}{ |P{2cm}|P{1cm}|P{1cm}|P{1cm}|P{1.8cm}| } 
            \multicolumn{5}{c}{\textbf{Evaluating algorithm}} \\
            \hline
            & \multicolumn{3}{c|}{\textbf{Random Forest}} & \\
            \hline
            \rowcolor{lightgray}
            & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{Support} \\
            \hline
            \textbf{0} & 0.88 & 0.92 & 0.90 & 1949 \\
            \hline
            \rowcolor{lightgray}
            \textbf{1} & 0.92 & 0.87 & 0.90 & 2043 \\
            \hline
            \textbf{2} & 0.92 & 0.87 & 0.90 & 2043 \\
            \hline
            \rowcolor{lightgray}
            \textbf{Accuracy} & \multicolumn{3}{c|}{0.8987975951903807} & 3992 \\
            \hline
            \textbf{Macro AVG} & 0.90 & 0.90 & 0.90 & 3992 \\
            \hline
            \rowcolor{lightgray}
            \textbf{Weighted AVG} & 0.90 & 0.90 & 0.90 & 3992 \\
            \hline
        \end{tabular}
        \caption{P = Precision, R = Recall e F1 = F1-score}
    \end{center}
\end{table}


\end{document}